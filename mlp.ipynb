{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载词向量模型\n",
    "word_vector_dict = KeyedVectors.load_word2vec_format(\n",
    "    \"./Dataset/wiki_word2vec_50.bin\", binary=True\n",
    ")\n",
    "\n",
    "# 确定词向量的维度\n",
    "vector_size = word_vector_dict.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从文件中读取数据\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        label = torch.tensor(float(parts[0]))\n",
    "        words = parts[1:]\n",
    "\n",
    "        word_vectors = []\n",
    "\n",
    "        for word in words:\n",
    "            if word in word_vector_dict:\n",
    "                word_vector = word_vector_dict[word]\n",
    "                word_vectors.append(word_vector)\n",
    "\n",
    "        word_vectors = np.array(word_vectors)\n",
    "\n",
    "        if len(word_vectors) > 0:\n",
    "            sentence_vector = torch.tensor(word_vectors).view(-1, vector_size)\n",
    "            sentences.append(sentence_vector)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Empty sentence: {line}\")\n",
    "\n",
    "    return {\n",
    "        \"sentences\": sentences,\n",
    "        \"labels\": labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty sentence: 0\t鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆 鸟爆\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "train_data = load_data(\"./Dataset/train.txt\")\n",
    "valid_data = load_data(\"./Dataset/validation.txt\")\n",
    "test_data = load_data(\"./Dataset/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将句子填充到相同长度\n",
    "def unify_columns(matrix, unified_length):\n",
    "    col_length, row_length = matrix.size()\n",
    "    if col_length > unified_length:\n",
    "        new_matrix = matrix[:unified_length, :]\n",
    "    elif col_length < unified_length:\n",
    "        padding = torch.zeros(unified_length - col_length, row_length)\n",
    "        new_matrix = torch.cat((matrix, padding), dim=0)\n",
    "    else:\n",
    "        new_matrix = matrix\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# 定义数据集类\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, sentences_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.sentence_len = sentences_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index].float()\n",
    "        label = self.labels[index]\n",
    "        output_matrix = unify_columns(sentence, self.sentence_len).view(-1).requires_grad_()\n",
    "        return output_matrix, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 19997\n",
      "验证集大小: 5629\n",
      "测试集大小: 369\n"
     ]
    }
   ],
   "source": [
    "# 创建Dataset对象\n",
    "SENTENCE_LEN = 64\n",
    "train_dataset = SentimentDataset(\n",
    "    train_data[\"sentences\"], train_data[\"labels\"], sentences_len=SENTENCE_LEN\n",
    ")\n",
    "valid_dataset = SentimentDataset(\n",
    "    valid_data[\"sentences\"], valid_data[\"labels\"], sentences_len=SENTENCE_LEN\n",
    ")\n",
    "test_dataset = SentimentDataset(\n",
    "    test_data[\"sentences\"], test_data[\"labels\"], sentences_len=SENTENCE_LEN\n",
    ")\n",
    "\n",
    "print(\"训练集大小:\", len(train_dataset))\n",
    "print(\"验证集大小:\", len(valid_dataset))\n",
    "print(\"测试集大小:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPSentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(MLPSentimentClassifier, self).__init__()\n",
    "\n",
    "        # 输入层\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # 隐藏层\n",
    "        self.hidden_layers = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, hidden_dim) for _ in range(3)]  # 假设有3个隐藏层\n",
    "        )\n",
    "\n",
    "        # Dropout层\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # 通过输入层\n",
    "        x = F.relu(self.input_layer(text))\n",
    "\n",
    "        # 通过隐藏层\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "\n",
    "        # 通过Dropout层\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # 通过输出层\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        # 使用sigmoid激活函数\n",
    "        probs = F.sigmoid(logits)\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPSentimentClassifier(\n",
      "  (input_layer): Linear(in_features=3200, out_features=256, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "INPUT_DIM = vector_size * SENTENCE_LEN\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# 初始化模型\n",
    "model = MLPSentimentClassifier(\n",
    "    INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT\n",
    ")\n",
    "\n",
    "# 查看模型结构\n",
    "print(model)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16, Train Loss: 0.6465, Valid Loss: 0.6405, Train Accuracy: 0.6660, Valid Accuracy: 0.6569\n",
      "Epoch 2/16, Train Loss: 0.6187, Valid Loss: 0.6289, Train Accuracy: 0.7374, Valid Accuracy: 0.7371\n",
      "Epoch 3/16, Train Loss: 0.6114, Valid Loss: 0.6254, Train Accuracy: 0.7566, Valid Accuracy: 0.7114\n",
      "Epoch 4/16, Train Loss: 0.6082, Valid Loss: 0.6290, Train Accuracy: 0.7637, Valid Accuracy: 0.7425\n",
      "Epoch 5/16, Train Loss: 0.6017, Valid Loss: 0.6377, Train Accuracy: 0.7795, Valid Accuracy: 0.7419\n",
      "Epoch 6/16, Train Loss: 0.5987, Valid Loss: 0.6265, Train Accuracy: 0.7852, Valid Accuracy: 0.7160\n",
      "Epoch 7/16, Train Loss: 0.5954, Valid Loss: 0.6307, Train Accuracy: 0.7930, Valid Accuracy: 0.7373\n",
      "Epoch 8/16, Train Loss: 0.6133, Valid Loss: 0.6398, Train Accuracy: 0.7560, Valid Accuracy: 0.7291\n",
      "Epoch 9/16, Train Loss: 0.5972, Valid Loss: 0.6271, Train Accuracy: 0.7911, Valid Accuracy: 0.7362\n",
      "Epoch 10/16, Train Loss: 0.5898, Valid Loss: 0.6308, Train Accuracy: 0.8075, Valid Accuracy: 0.7009\n",
      "Epoch 11/16, Train Loss: 0.5860, Valid Loss: 0.6266, Train Accuracy: 0.8156, Valid Accuracy: 0.7280\n",
      "Epoch 12/16, Train Loss: 0.5832, Valid Loss: 0.6300, Train Accuracy: 0.8243, Valid Accuracy: 0.7029\n",
      "Epoch 13/16, Train Loss: 0.5815, Valid Loss: 0.6328, Train Accuracy: 0.8298, Valid Accuracy: 0.7000\n",
      "Epoch 14/16, Train Loss: 0.5830, Valid Loss: 0.6278, Train Accuracy: 0.8222, Valid Accuracy: 0.7306\n",
      "Epoch 15/16, Train Loss: 0.5792, Valid Loss: 0.6276, Train Accuracy: 0.8330, Valid Accuracy: 0.7353\n",
      "Epoch 16/16, Train Loss: 0.5753, Valid Loss: 0.6282, Train Accuracy: 0.8419, Valid Accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# 定义准确率计算函数\n",
    "def accuracy(logits, labels):\n",
    "    labels = labels.view(-1, 1)\n",
    "    y_pred = logits >= 0.5\n",
    "    y = labels == 1\n",
    "    correct_predictions = (y_pred == y).float()\n",
    "    correct_predictions = correct_predictions.view(-1)\n",
    "    accuracy = correct_predictions.sum() / len(labels)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, loss_function, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for sentences, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(sentences)\n",
    "        loss = loss_function(logits, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        batch_accuracy = accuracy(logits, labels)\n",
    "        total_accuracy += batch_accuracy.item()\n",
    "\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    average_accuracy = total_accuracy / len(data_loader)\n",
    "    return average_loss, average_accuracy\n",
    "\n",
    "\n",
    "def valid_epoch(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for sentences, labels in data_loader:\n",
    "            logits = model(sentences)\n",
    "            loss = loss_function(logits, labels.unsqueeze(1))\n",
    "            total_loss += loss.item()\n",
    "            batch_accuracy = accuracy(logits, labels)\n",
    "            total_accuracy += batch_accuracy.item()\n",
    "\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    average_accuracy = total_accuracy / len(data_loader)\n",
    "    return average_loss, average_accuracy\n",
    "\n",
    "\n",
    "# 开始训练，包括准确率的打印\n",
    "num_epochs = 16\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train_epoch(\n",
    "        model, train_loader, loss_function, optimizer\n",
    "    )\n",
    "    valid_loss, valid_accuracy = valid_epoch(model, valid_loader, loss_function)\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, \"\n",
    "        f\"Train Accuracy: {train_accuracy:.4f}, Valid Accuracy: {valid_accuracy:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6369, Test Accuracy: 0.7099\n"
     ]
    }
   ],
   "source": [
    "# 测试循环以评估模型性能\n",
    "def test_epoch(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for sentences, labels in data_loader:\n",
    "            logits = model(sentences)\n",
    "            loss = loss_function(logits, labels.unsqueeze(1))\n",
    "            total_loss += loss.item()\n",
    "            batch_accuracy = accuracy(logits, labels)\n",
    "            total_accuracy += batch_accuracy.item()\n",
    "\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    average_accuracy = total_accuracy / len(data_loader)\n",
    "    return average_loss, average_accuracy\n",
    "\n",
    "\n",
    "# 在训练完成后，评估模型在测试集上的性能\n",
    "test_loss, test_accuracy = test_epoch(model, test_loader, loss_function)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"mlp_sentiment_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(probs, labels):\n",
    "    probs = probs.view(-1)\n",
    "    y_true = list(labels == 1)\n",
    "    for i in range(len(y_true)):\n",
    "        y_true[i] = y_true[i].item()\n",
    "    print(y_true)\n",
    "    y_pred = list(probs >= 0.5)\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = y_pred[i].item()\n",
    "    print(y_pred)\n",
    "    true_positives = sum([1 for y, p in zip(y_true, y_pred) if y == True and p == True])\n",
    "    false_positives = sum(\n",
    "        [1 for y, p in zip(y_true, y_pred) if y == False and p == True]\n",
    "    )\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall_score(probs, labels):\n",
    "    probs = probs.view(-1)\n",
    "    y_true = list(labels == 1)\n",
    "    for i in range(len(y_true)):\n",
    "        y_true[i] = y_true[i].item()\n",
    "\n",
    "    y_pred = list(probs >= 0.5)\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = y_pred[i].item()\n",
    "\n",
    "    true_positives = sum([1 for y, p in zip(y_true, y_pred) if y == True and p == True])\n",
    "    false_negatives = sum(\n",
    "        [1 for y, p in zip(y_true, y_pred) if y == True and p == False]\n",
    "    )\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPSentimentClassifier(\n",
       "  (input_layer): Linear(in_features=3200, out_features=256, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "model.load_state_dict(torch.load(\"mlp_sentiment_model.pth\"))\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, True, False, False, False, True, True, False, False, True, True, True, False, False, False, False, False, True, True, True, False, True, True, False, False, False, False, True, True, False, False, True, False, False, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, False, False, True, False, True, True, False, False, True, True, False, False, True, False, False, True, True, False, False, False, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, False, False, False, True, True, True, False, False, False, True, False, False, True, False, True, True, True, False, True, True, False, True, True, False, False, True, True, True, True, True, True, False, True, True, True, False, True, False, True, True, False, True, True, True, False, True, False, False, False, True, False, False, False, False, False, True, True, False, False, False, True, False, True, False, False, False, False, True, False, False, True, True, False, False, False, False, True, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, True, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, True, False, False, True, True, False]\n",
      "Average Loss: 0.6279\n",
      "Average Accuracy: 0.7100\n",
      "Average Precision: 0.7817\n",
      "Average Recall: 0.5936\n",
      "Average F1 Score: 0.6748\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "total_loss = 0\n",
    "total_accuracy = 0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for sentences, labels in test_loader:\n",
    "        probs = model(sentences)\n",
    "\n",
    "        batch_loss = loss_function(probs, labels.unsqueeze(1))\n",
    "        total_loss += batch_loss.item()\n",
    "\n",
    "        batch_accuracy = accuracy(probs, labels)\n",
    "        total_accuracy += batch_accuracy.item()\n",
    "\n",
    "        # 计算精确率、召回率和F-score\n",
    "        batch_precision = precision_score(probs, labels)\n",
    "        batch_recall = recall_score(probs, labels)\n",
    "\n",
    "        total_precision += batch_precision\n",
    "        total_recall += batch_recall\n",
    "\n",
    "average_loss = total_loss / len(test_loader)\n",
    "average_accuracy = total_accuracy / len(test_loader)\n",
    "average_precision = total_precision / len(test_loader)\n",
    "average_recall = total_recall / len(test_loader)\n",
    "average_f1 = 2 * ((average_precision * average_recall) / (average_precision + average_recall))\n",
    "\n",
    "print(f\"Average Loss: {average_loss:.4f}\")\n",
    "print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {average_precision:.4f}\")\n",
    "print(f\"Average Recall: {average_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {average_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
